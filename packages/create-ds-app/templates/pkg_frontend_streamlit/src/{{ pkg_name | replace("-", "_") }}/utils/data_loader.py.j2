"""Data loading utilities."""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import streamlit as st


@st.cache_data(ttl=3600)
def load_sample_data():
    """Load sample data for demonstration."""
    # Generate sample time series data
    dates = pd.date_range(
        start=datetime.now() - timedelta(days=90),
        end=datetime.now(),
        freq="D"
    )

    df = pd.DataFrame({
        "date": dates,
        "value": np.cumsum(np.random.randn(len(dates))) + 100,
        "volume": np.random.randint(1000, 5000, size=len(dates)),
        "category": np.random.choice(["A", "B", "C", "D"], size=len(dates)),
    })

    return df


@st.cache_data
def load_csv(file_path: str) -> pd.DataFrame:
    """Load CSV file with caching."""
    return pd.read_csv(file_path)


@st.cache_data
def fetch_api_data(endpoint: str, params: dict = None) -> dict:
    """Fetch data from API with caching."""
    import requests
    from {{ pkg_name | replace("-", "_") }}.config import settings

    url = f"{settings.api_url}/{endpoint}"
    response = requests.get(url, params=params)
    response.raise_for_status()

    return response.json()


def filter_dataframe(df: pd.DataFrame, filters: dict) -> pd.DataFrame:
    """Apply filters to a dataframe."""
    filtered_df = df.copy()

    # Date range filter
    if "start_date" in filters and "end_date" in filters:
        if "date" in filtered_df.columns:
            filtered_df = filtered_df[
                (filtered_df["date"] >= pd.to_datetime(filters["start_date"])) &
                (filtered_df["date"] <= pd.to_datetime(filters["end_date"]))
            ]

    # Category filter
    if "categories" in filters and filters["categories"]:
        if "category" in filtered_df.columns:
            filtered_df = filtered_df[filtered_df["category"].isin(filters["categories"])]

    # Numeric range filter
    if "min_value" in filters and "max_value" in filters:
        if "value" in filtered_df.columns:
            filtered_df = filtered_df[
                (filtered_df["value"] >= filters["min_value"]) &
                (filtered_df["value"] <= filters["max_value"])
            ]

    return filtered_df


def aggregate_data(df: pd.DataFrame, aggregation: str = "Daily") -> pd.DataFrame:
    """Aggregate data based on specified frequency."""
    if "date" not in df.columns:
        return df

    freq_map = {
        "Daily": "D",
        "Weekly": "W",
        "Monthly": "M",
    }

    freq = freq_map.get(aggregation, "D")

    # Group by date with specified frequency
    df["date"] = pd.to_datetime(df["date"])
    aggregated = df.set_index("date").resample(freq).agg({
        col: "sum" if df[col].dtype in ["int64", "float64"] else "first"
        for col in df.columns if col != "date"
    }).reset_index()

    return aggregated